1. Write a SQL query to find the top 3 products by total sales for each region in the last 6 months. Ensure ties are handled properly.
2. Given a sales table with order_date and ship_date, find orders where shipping took more than the average shipping time for that month.
3. You have an employee table with hierarchical data (employee_id, manager_id). Write a recursive query to list all subordinates for a given manager.
4. How would you identify and remove duplicate records in a huge table while keeping the most recent one based on a timestamp column?
5. You receive a large CSV file (20 GB) daily. How would you efficiently read, transform, and write it to a database using Python?
6. Write a Python function to detect anomalies in daily sales data, such as sudden spikes or drops beyond 3 standard deviations from the mean.
7. Given a list of transactions, group them by customer and return the top N customers by purchase frequency without using built-in libraries like Pandas.
8. You have daily sales data in multiple small CSV files in ADLS/S3. How would you optimize reading them in PySpark to avoid the small file problem?
9. Explain how you would design a PySpark job to join two very large datasets (billions of rows each) efficiently.
10. How would you handle skew in a Spark join where one key has significantly more data than others?
11. How would you design a data model for a global supply chain system that needs both historical trend analysis and real-time tracking?
12. What is your approach to implementing Slowly Changing Dimensions (SCD) Type 2 in a data warehouse?
13. PepsiCo sources data from multiple ERP systems with different schemas. How would you unify the schema for consistent reporting?
14. Describe how you would design a real-time order tracking pipeline using Kafka, Spark Streaming, and a cloud storage/data warehouse layer.
15. You need to move a 10 TB historical dataset from on-prem SQL Server to Azure Synapse while minimizing downtime. How would you approach it?